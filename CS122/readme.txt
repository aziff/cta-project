Short directions:
	1. Download Data folder with predictions (generated from get_api_data.py and manually compiled)
	2. In terminal, run
	           python clean.py
    3. Enter R environment by typing R
        a. Run install.packages("KernSmooth") and follow directions
    	b. Run source("cta_predictions.R")
    	c. Run q() and don't save workspace image
    4. Django
        a. Navigate to ui/data
        b. In terminal, run
               sqlite3 no_quotes2.db < create_db.sql
        c. Navigate to project/ui
        d. In terminal, type
               python manage.py runserver
        e. Follow the available link and enter queries

All output for python and R files goes to a folder called Output, which is made in clean.py
Because of the size of our data, the code can run quite slowly on VM machines. Please be patient!
There are some queries that do not work and we were unable to debug them.



Information:

Data collection:
get_api_data.py

get_api_data.py creates 4 csv files, one for each route. We used the CTA API to collect data. Each request to the API returned bus predictions for the stops indicated in an xml file. That xml file contained prediction data among which included time. Early on in our project we noticed that the time a prediction was created was not always actual time, ie: we make a request at 8:25 and the prediction says the current time is 8:24, so we made a separate request for the real time. Our function make_xml(xmlname, request_function) makes the API request.

Next, we parsed the xml file and wrote the following information into a csv file: the stop id, the time the prediction was created, the real time the prediction was requested, the location of the stop, the time CTA predicts the bus will arrive and the vehicle id of the bus going to that stop. Our function parse_xml(xmlfile_time, xmlfile_pred, csvfile) parses the xml file and creates a csv file with a filename that includes the route, date and time the first request was made.
    Everyday we edited lines 65-69 so they indicated the correct date and time the data was first collected. Every time we run collect_data.py it creates the csv file for a given date if that file does not already exist or it adds to the already existing file. We collected data for approximately 18 hours a day and we did so using bash in the terminal. we used this code:
---------------------------------------------------------------------------
#!/bin/bash
n=1
while [ $n -le x ]
do
    echo "$n"
    python get_api_data.py
    n=$(( n+1 ))
    sleep 30
done
-------------------------------------------------------------------------------
to run get_api_data.py every 30 seconds. x was the number of minutes we wanted to collect data times two. ie: for one hour, x=120

Organizing Data:
clean.py

    This file takes the csv files with all the prediction data and organizes it.

route_day_dict(filename, date) takes a filename and the date and puts the bus time, real time and prediction time into a dictionary organized by date and stop. This dictionary is nested inside a date dictionary in our main function.


data_dict[6][2-18-15][12306][1400][1] = [732 733 734]
data_dict[6][2-18-15][12306][1400][2] = [733 733 734]
data_dict[6][2-18-15][12306][1400][3] = [734 734 735]
data_dict[6][2-18-15][12306][1400][4] = [734 734 750 ]

where_art_thou_bus(data_dict) takes our data dictionary (which is generated by our main function and is organized by route, date, stop id, and vehicle id) and appends:
how far in advance a prediction was made relative to the bus time
how far in advance a prediction was made relative to the real time
how inaccurate the bus prediction was
how inaccurate the real prediction was
the arrival time
 to each corresponding prediction ie: data_dict[6][2-18-15][12306][1400][1] = [732, 733,735, 3, 2, -1, -1,734]. where_art_thou_bus figures out when the bus has arrived by tracking the time difference between when the predictions in the list for a given vehicle id were acquired and the time difference between the actual times predicted. In the example predictions, the  time difference between line 3 and 4 is 1 but the time difference between the predictions  for lines 3 and 4 is so large that the bus must have arrived.

mk_dist_dict(data_dict) takes our updated data dictionary called distribution and adds all the predictions with arrival data to the new dictionary. This new dictionary is organized by route and stop. Each stop dictionary contains two dictionaries: Bus and Official. Bus contains dictionaries for how far in advance the prediction was made relative to “bus time”. Official contains dictionaries for how far in advance the prediction was made relative to the real time. Each prediction dictionary contains a list of the prediction errors
ie: distribution[6][12306][“Bus”][7]=[-1,1,2,-2,5,2,1,3…]
     distribution[6][12306][“Official”][7]=[0,0,1,1,0,1,2,0…]

mk_avg_dist_dict(data_dict) is similar to the function above except it makes the distribution dictionaries to get the time-aggregated errors for each route and stop. This is useful for analysis.

mk_r_csv(route,stop, distribution) take the route number, stop id, and a distribution dictionary makes txt files for each prediction error in each category. ie: 0_6_1651_Official.txt contains all the errors for predictions made 0 minutes in advance for stop 1651 for the 6 route.

mk_avg_r_csv(route, stop, distribution) is the same as above excpet it appends "AVG" to the beginnning of the filename. Both of these functions deposit the .txt files into the Output folder, which is created if it does not exist.

Analyzing Data:
cta_predictions.R

Before running this code, first open R in the terminal and run the following code to install the requistite package:

---------------------------------------------------------------------------
install.packages("KernSmooth")
---------------------------------------------------------------------------

This R code takes the .txt files created by clean.py and compiles them into one .csv file that will then be the basis for our SQL database. The loop goes through all the prediction times between 0 and 30, all the routes, and all the stops. At each point, it appends the bus, the stop, the type (bus or official time), and the upper and lower prediction errors (+/- one half of a standard deviation) each to separate vectors. Once it has created the vectors, the dataframe is created by binding them together, and the dataframe is then output to a .csv file.
